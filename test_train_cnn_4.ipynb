{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/congyu/.virtualenvs/congyuml/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/congyu/.virtualenvs/congyuml/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/congyu/.virtualenvs/congyuml/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/congyu/.virtualenvs/congyuml/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/congyu/.virtualenvs/congyuml/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/congyu/.virtualenvs/congyuml/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/congyu/.virtualenvs/congyuml/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/congyu/.virtualenvs/congyuml/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/congyu/.virtualenvs/congyuml/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/congyu/.virtualenvs/congyuml/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/congyu/.virtualenvs/congyuml/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/congyu/.virtualenvs/congyuml/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/congyu/congyu_program/pythons/forks/ECGNeuralNetwork\n"
     ]
    }
   ],
   "source": [
    "from cnn.cnn import load_dataset, create_model, steps\n",
    "from dataset import dataset, load_files\n",
    "from utilities.labels import LABELS\n",
    "from dataset.data_augmentation import augmentated_filenames2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"./data/mit_bih/\"\n",
    "save_dir = \"./data/beats_img/\"\n",
    "_dataset_dir = './data/beats_img'\n",
    "_model = './trained_models/cnn_aami_baseline_compare.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = None\n",
    "validation = None\n",
    "augmentation = False\n",
    "_batch_size = 32\n",
    "_size = (64, 64)\n",
    "_epochs = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/congyu/.virtualenvs/congyuml/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4070: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "AEB: 16\t\n",
      "APC: 2544\t\n",
      "FUS: 803\t\n",
      "JEB: 229\t\n",
      "JPB: 83\t\n",
      "LBB: 8072\t\n",
      "NOR: 75016\t\n",
      "PAB: 7024\t\n",
      "PVC: 7130\t\n",
      "RBB: 7256\t\n",
      "SVP: 2\t\n",
      "VEB: 106\t\n",
      "VFW: 472\t\n",
      "aPC: 150\t\n",
      "7622\n",
      "1633\n",
      "1634\n"
     ]
    }
   ],
   "source": [
    "model = create_model(out_dim=4)\n",
    "\n",
    "train, validation, test = dataset.load_files(_dataset_dir, \n",
    "                                             verbose=True, \n",
    "                                             keep_ratio=0.1)\n",
    "    \n",
    "print(len(train))\n",
    "print(len(validation))\n",
    "print(len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/congyu/.virtualenvs/congyuml/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch 1/30\n",
      "239/238 [==============================] - 125s 525ms/step - loss: 0.4928 - accuracy: 0.9142 - val_loss: 0.7626 - val_accuracy: 0.9030\n",
      "Epoch 2/30\n",
      "239/238 [==============================] - 18s 76ms/step - loss: 0.2959 - accuracy: 0.9467 - val_loss: 0.3289 - val_accuracy: 0.9219\n",
      "Epoch 3/30\n",
      "239/238 [==============================] - 18s 76ms/step - loss: 0.2368 - accuracy: 0.9562 - val_loss: 0.3975 - val_accuracy: 0.9170\n",
      "Epoch 4/30\n",
      "239/238 [==============================] - 18s 77ms/step - loss: 0.2024 - accuracy: 0.9663 - val_loss: 0.2600 - val_accuracy: 0.8969\n",
      "Epoch 5/30\n",
      "239/238 [==============================] - 18s 77ms/step - loss: 0.1862 - accuracy: 0.9680 - val_loss: 0.2587 - val_accuracy: 0.9121\n",
      "Epoch 6/30\n",
      "239/238 [==============================] - 18s 77ms/step - loss: 0.1668 - accuracy: 0.9738 - val_loss: 0.4346 - val_accuracy: 0.9445\n",
      "Epoch 7/30\n",
      "239/238 [==============================] - 18s 77ms/step - loss: 0.1616 - accuracy: 0.9729 - val_loss: 0.4706 - val_accuracy: 0.9457\n",
      "Epoch 8/30\n",
      "239/238 [==============================] - 18s 77ms/step - loss: 0.1505 - accuracy: 0.9773 - val_loss: 0.1728 - val_accuracy: 0.9664\n",
      "Epoch 9/30\n",
      "239/238 [==============================] - 18s 77ms/step - loss: 0.1466 - accuracy: 0.9809 - val_loss: 0.3290 - val_accuracy: 0.9628\n",
      "Epoch 10/30\n",
      "239/238 [==============================] - 18s 77ms/step - loss: 0.1449 - accuracy: 0.9827 - val_loss: 0.1470 - val_accuracy: 0.9677\n",
      "Epoch 11/30\n",
      "239/238 [==============================] - 18s 77ms/step - loss: 0.1420 - accuracy: 0.9841 - val_loss: 0.1295 - val_accuracy: 0.9646\n",
      "Epoch 12/30\n",
      "239/238 [==============================] - 18s 77ms/step - loss: 0.1308 - accuracy: 0.9872 - val_loss: 0.0957 - val_accuracy: 0.9740\n",
      "Epoch 13/30\n",
      "239/238 [==============================] - 18s 75ms/step - loss: 0.1277 - accuracy: 0.9887 - val_loss: 0.6351 - val_accuracy: 0.9201\n",
      "Epoch 14/30\n",
      "239/238 [==============================] - 19s 78ms/step - loss: 0.1219 - accuracy: 0.9901 - val_loss: 0.0903 - val_accuracy: 0.9671\n",
      "Epoch 15/30\n",
      "239/238 [==============================] - 18s 76ms/step - loss: 0.1189 - accuracy: 0.9900 - val_loss: 0.1568 - val_accuracy: 0.9512\n",
      "Epoch 16/30\n",
      "239/238 [==============================] - 18s 76ms/step - loss: 0.1200 - accuracy: 0.9891 - val_loss: 0.0911 - val_accuracy: 0.9725\n",
      "Epoch 17/30\n",
      "239/238 [==============================] - 19s 78ms/step - loss: 0.1213 - accuracy: 0.9907 - val_loss: 0.2700 - val_accuracy: 0.8981\n",
      "Epoch 18/30\n",
      "239/238 [==============================] - 18s 77ms/step - loss: 0.1067 - accuracy: 0.9942 - val_loss: 0.1674 - val_accuracy: 0.9567\n",
      "Epoch 19/30\n",
      "239/238 [==============================] - 18s 77ms/step - loss: 0.0969 - accuracy: 0.9957 - val_loss: 0.2262 - val_accuracy: 0.9683\n",
      "Epoch 20/30\n",
      "239/238 [==============================] - 18s 77ms/step - loss: 0.0994 - accuracy: 0.9942 - val_loss: 0.0878 - val_accuracy: 0.9707\n",
      "Epoch 21/30\n",
      "239/238 [==============================] - 18s 77ms/step - loss: 0.1029 - accuracy: 0.9931 - val_loss: 0.6804 - val_accuracy: 0.8963\n",
      "Epoch 22/30\n",
      "239/238 [==============================] - 18s 77ms/step - loss: 0.0990 - accuracy: 0.9928 - val_loss: 0.2327 - val_accuracy: 0.9701\n",
      "Epoch 23/30\n",
      "239/238 [==============================] - 19s 78ms/step - loss: 0.0913 - accuracy: 0.9953 - val_loss: 0.1947 - val_accuracy: 0.9646\n",
      "Epoch 24/30\n",
      "239/238 [==============================] - 19s 78ms/step - loss: 0.0812 - accuracy: 0.9971 - val_loss: 0.0728 - val_accuracy: 0.9789\n",
      "Epoch 25/30\n",
      "239/238 [==============================] - 19s 77ms/step - loss: 0.0781 - accuracy: 0.9966 - val_loss: 0.0680 - val_accuracy: 0.9774\n",
      "Epoch 26/30\n",
      "239/238 [==============================] - 19s 78ms/step - loss: 0.0799 - accuracy: 0.9961 - val_loss: 0.2181 - val_accuracy: 0.9725\n",
      "Epoch 27/30\n",
      "239/238 [==============================] - 19s 78ms/step - loss: 0.0765 - accuracy: 0.9961 - val_loss: 0.0640 - val_accuracy: 0.9756\n",
      "Epoch 28/30\n",
      "239/238 [==============================] - 18s 77ms/step - loss: 0.0712 - accuracy: 0.9968 - val_loss: 0.0619 - val_accuracy: 0.9750\n",
      "Epoch 29/30\n",
      "239/238 [==============================] - 19s 77ms/step - loss: 0.0669 - accuracy: 0.9987 - val_loss: 0.1696 - val_accuracy: 0.9695\n",
      "Epoch 30/30\n",
      "239/238 [==============================] - 19s 78ms/step - loss: 0.0692 - accuracy: 0.9967 - val_loss: 0.1665 - val_accuracy: 0.9512\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7fbcdf23fa58>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if augmentation:\n",
    "    train = augmentated_filenames2(train)\n",
    "\n",
    "callbacks_list = [ModelCheckpoint(_model, monitor='val_loss', save_best_only=False),\n",
    "                  EarlyStopping(monitor='val_loss', min_delta=0, patience=10, verbose=0, mode='auto',\n",
    "                                baseline=None, restore_best_weights=False),\n",
    "                  ReduceLROnPlateau(monitor='val_loss', factor=0.8, patience=3, verbose=0, mode='auto')\n",
    "# TrainValTensorBoard(write_graph=False)\n",
    "]\n",
    "\n",
    "data_gen_train = load_dataset(train, _dataset_dir,\n",
    "                              _batch_size, _size,\n",
    "                              label_type = \"AAMI\",\n",
    "                              random_crop=augmentation,\n",
    "                              random_rotate=augmentation,\n",
    "                              flip=augmentation)\n",
    "\n",
    "data_gen_valid = load_dataset(validation, _dataset_dir,\n",
    "                              _batch_size, _size,\n",
    "                              label_type = \"AAMI\",\n",
    "                              random_crop=augmentation,\n",
    "                              random_rotate=augmentation,\n",
    "                              flip=augmentation)\n",
    "\n",
    "model.fit_generator(data_gen_train,\n",
    "                    steps_per_epoch=steps(train, _batch_size),\n",
    "                    epochs=_epochs,\n",
    "                    validation_data=data_gen_valid,\n",
    "                    validation_steps=steps(validation, _batch_size),\n",
    "                    callbacks=callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "model = load_model(_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluation import evaluate_cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "changing 1530 images to arrays\n",
      "predicting on 1530 samples\n",
      "precision:  0.953116410942864\n",
      "recall:  0.9490196078431372\n",
      "f1score:  0.9485758255174623\n",
      "marco f1 score 0.6737648530733986\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Number of classes, 4, does not match size of target_names, 3. Try specifying the labels parameter",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-650d899598bb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mevaluate_cnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"AAMI\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeep_ratio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/congyu_program/pythons/forks/ECGNeuralNetwork/evaluation.py\u001b[0m in \u001b[0;36mevaluate_cnn\u001b[0;34m(model, label_type, keep_ratio, verbose)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"marco f1 score\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'macro'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_names\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mAAMI_LABELS\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/congyuml/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m                           FutureWarning)\n\u001b[1;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.virtualenvs/congyuml/lib/python3.6/site-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mclassification_report\u001b[0;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict, zero_division)\u001b[0m\n\u001b[1;32m   1951\u001b[0m                 \u001b[0;34m\"Number of classes, {0}, does not match size of \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1952\u001b[0m                 \u001b[0;34m\"target_names, {1}. Try specifying the labels \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1953\u001b[0;31m                 \u001b[0;34m\"parameter\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1954\u001b[0m             )\n\u001b[1;32m   1955\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtarget_names\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Number of classes, 4, does not match size of target_names, 3. Try specifying the labels parameter"
     ]
    }
   ],
   "source": [
    "evaluate_cnn(model, label_type=\"AAMI\", keep_ratio=0.1)\n",
    "print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "congyuml",
   "language": "python",
   "name": "congyuml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
